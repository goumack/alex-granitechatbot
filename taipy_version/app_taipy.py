"""
ALEX - Version simplifi√©e avec interface Flask moderne
Version entreprise √©l√©gante et professionnelle
"""
# FIX: SQLite version pour chromadb (avant tout import de chromadb)
import sys
try:
    import pysqlite3
    sys.modules['sqlite3'] = pysqlite3
except ImportError:
    pass

import os
from flask import Flask, render_template_string, request, jsonify
import requests
import json
from typing import List, Dict, Optional
import chromadb
from chromadb.config import Settings
from dotenv import load_dotenv
import logging
import threading
import time
import hashlib
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from collections import OrderedDict
from openai import OpenAI
import urllib3

# D√©sactiver les avertissements SSL (certificat expir√© sur Ollama)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Configuration des logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Charger la configuration depuis le fichier .env
# Chercher le fichier .env dans le r√©pertoire parent
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
    logger.info(f"Configuration charg√©e depuis: {env_path}")
else:
    load_dotenv()
    logger.info("Configuration charg√©e depuis .env par d√©faut")

class ALEXProConfig:
    """Configuration ALEX - Hybride Ollama (embeddings) + NVIDIA NIM (chat)"""
    # Configuration Ollama pour les embeddings
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "https://ollamaaccel-chatbotaccel.apps.senum.heritage.africa")
    OLLAMA_EMBEDDING_MODEL = os.getenv("OLLAMA_EMBEDDING_MODEL", "nomic-embed-text")

    # Configuration NVIDIA NIM pour le chat
    NVIDIA_API_KEY = os.getenv("NVIDIA_API_KEY", "")
    NVIDIA_BASE_URL = os.getenv("NVIDIA_BASE_URL", "https://integrate.api.nvidia.com/v1")
    NVIDIA_CHAT_MODEL = os.getenv("NVIDIA_CHAT_MODEL", "mistralai/mistral-7b-instruct-v0.3")

    CHROMA_PERSIST_DIRECTORY = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
    WATCH_DIRECTORY = os.getenv("WATCH_DIRECTORY", "./documents")  # R√©pertoire √† surveiller
    SUPPORTED_EXTENSIONS = ['.txt', '.pdf', '.docx', '.md', '.json', '.csv', '.odt']

    # V√©rifier que la cl√© API est charg√©e
    if not NVIDIA_API_KEY:
        logger.warning("‚ö†Ô∏è NVIDIA_API_KEY non trouv√©e dans les variables d'environnement!")
    else:
        logger.info(f"‚úÖ NVIDIA_API_KEY charg√©e (longueur: {len(NVIDIA_API_KEY)})")

class DocumentWatcherHandler(FileSystemEventHandler):
    """Gestionnaire de surveillance automatique en arri√®re-plan"""
    
    def __init__(self, alex_client):
        self.alex_client = alex_client
        self.processing_queue = []
        self.last_processed = {}
        super().__init__()
    
    def on_created(self, event):
        """Nouveau fichier cr√©√© - Indexation automatique en arri√®re-plan"""
        if not event.is_directory:
            file_path = event.src_path
            
            # Ignorer les fichiers temporaires et syst√®me
            file_name = Path(file_path).name
            if file_name.startswith(('~$', '.', '__pycache__')) or file_name.endswith('.tmp'):
                logger.debug(f"‚è≠ [AUTO] Fichier temporaire ignor√©: {file_name}")
                return
                
            logger.info(f"üìÑ [AUTO] Nouveau fichier d√©tect√©: {file_name}")
            
            # Traitement asynchrone en arri√®re-plan AVEC gestion d'erreur robuste
            import threading
            def delayed_process():
                try:
                    time.sleep(3)  # Attendre que le fichier soit compl√®tement √©crit (plus long pour Windows)
                    
                    # V√©rifier que le fichier existe encore et est accessible
                    if not os.path.exists(file_path):
                        logger.warning(f"‚ö†Ô∏è [AUTO] Fichier introuvable apr√®s d√©lai: {file_name}")
                        return
                    
                    # V√©rifier la taille du fichier pour s'assurer qu'il est complet
                    try:
                        initial_size = os.path.getsize(file_path)
                        time.sleep(1)
                        final_size = os.path.getsize(file_path)
                        if initial_size != final_size:
                            logger.info(f"üìù [AUTO] Fichier en cours d'√©criture, attente: {file_name}")
                            time.sleep(2)  # Attendre encore un peu
                    except OSError as e:
                        logger.warning(f"‚ö†Ô∏è [AUTO] Erreur v√©rification taille fichier {file_name}: {e}")
                    
                    if self.alex_client.is_supported_file(file_path):
                        logger.info(f"üîÑ [AUTO] D√©but indexation automatique: {file_name}")
                        self.alex_client.process_new_file_background(file_path)
                        logger.info(f"‚úÖ [AUTO] Fichier index√© automatiquement: {file_name}")
                    else:
                        logger.debug(f"‚è≠ [AUTO] Fichier ignor√© (format non support√©): {file_name}")
                        
                except FileNotFoundError:
                    logger.warning(f"‚ö†Ô∏è [AUTO] Fichier disparu pendant l'indexation: {file_name}")
                except PermissionError:
                    logger.warning(f"‚ö†Ô∏è [AUTO] Permissions insuffisantes pour {file_name}")
                except Exception as e:
                    logger.error(f"‚ùå [AUTO] Erreur indexation automatique {file_name}: {e}")
                    # En cas d'erreur, on peut essayer de forcer une r√©indexation manuelle plus tard
                    if hasattr(self.alex_client, '_failed_auto_files'):
                        self.alex_client._failed_auto_files.append(file_path)
            
            # Lancer en thread s√©par√© pour ne pas bloquer le syst√®me
            thread = threading.Thread(target=delayed_process, daemon=True, name=f"AutoIndex-{file_name}")
            thread.start()
    
    def on_modified(self, event):
        """Fichier modifi√© - R√©indexation automatique si n√©cessaire"""
        if not event.is_directory:
            file_path = event.src_path
            
            # Ignorer les fichiers temporaires et √©viter les doublons rapides
            if Path(file_path).name.startswith(('~$', '.')):
                return
                
            # √âviter le traitement en boucle (limitation par temps)
            current_time = time.time()
            if file_path in self.last_processed:
                if current_time - self.last_processed[file_path] < 5:  # 5 secondes minimum
                    return
            
            self.last_processed[file_path] = current_time
            logger.info(f"[AUTO] Modification d√©tect√©e: {Path(file_path).name}")
            
            # Traitement asynchrone en arri√®re-plan
            import threading
            def delayed_reprocess():
                try:
                    time.sleep(1)  # Attendre la fin de l'√©criture
                    if self.alex_client.is_supported_file(file_path):
                        self.alex_client.process_modified_file_background(file_path)
                        logger.info(f" [AUTO] Fichier r√©index√© automatiquement: {Path(file_path).name}")
                except Exception as e:
                    logger.error(f" [AUTO] Erreur r√©indexation automatique {Path(file_path).name}: {e}")
            
            # Lancer en thread s√©par√©
            thread = threading.Thread(target=delayed_reprocess, daemon=True)
            thread.start()

class ALEXProClient:
    """Client ALEX optimis√© avec surveillance automatique"""
    
    def __init__(self):
        self.config = ALEXProConfig()
        self.indexed_files = {}  # Cache des fichiers index√©s {path: hash}
        self.observer = None  # R√©f√©rence au watcher
        self._failed_auto_files = []  # Liste des fichiers qui ont √©chou√© en auto-indexation
        self._last_activity = time.time()  # Derni√®re activit√© de surveillance
        self.setup_chroma()
        self.setup_watch_directory()

        # Initialiser le client OpenAI pour NVIDIA NIM (chat uniquement)
        try:
            if not self.config.NVIDIA_API_KEY:
                logger.error("‚ùå NVIDIA_API_KEY est vide! V√©rifiez votre fichier .env")
                self.nvidia_client = None
            else:
                self.nvidia_client = OpenAI(
                    base_url=self.config.NVIDIA_BASE_URL,
                    api_key=self.config.NVIDIA_API_KEY
                )
                logger.info(f"‚úÖ Configuration Hybride initialis√©e:")
                logger.info(f"   Chat: NVIDIA NIM ({self.config.NVIDIA_CHAT_MODEL})")
                logger.info(f"   Embeddings: Ollama ({self.config.OLLAMA_EMBEDDING_MODEL})")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation client NVIDIA: {e}")
            self.nvidia_client = None

        # Pr√©parer session HTTP r√©utilisable et cache d'embeddings
        try:
            self._session = requests.Session()
            # Retry strategy for transient errors
            retries = Retry(total=3, backoff_factor=0.3, status_forcelist=(500,502,503,504))
            adapter = HTTPAdapter(max_retries=retries, pool_connections=10, pool_maxsize=20)
            self._session.mount('http://', adapter)
            self._session.mount('https://', adapter)
            self._session.headers.update({'Connection': 'keep-alive', 'User-Agent': 'ALEX-Pro/1.0'})
            # Ignorer la v√©rification SSL pour les certificats expir√©s
            self._session.verify = False
        except Exception:
            self._session = None

        # Small in-memory cache for embeddings to avoid redundant calls for identical chunks
        self.embedding_cache = {}

        # Simple LRU response cache for model outputs (query+context -> response)
        self.response_cache = OrderedDict()
        self.response_cache_max = int(os.getenv('ALEX_RESPONSE_CACHE_MAX', '500'))
        self.response_cache_ttl = int(os.getenv('ALEX_RESPONSE_CACHE_TTL', '3600'))  # seconds

        # D√©marrer automatiquement la surveillance en arri√®re-plan
        try:
            self.start_file_watcher()
        except Exception as e:
            logger.warning(f"  Surveillance automatique d√©sactiv√©e: {e}")

        logger.info("   ALEX initialis√© - Surveillance automatique active")
    
    def setup_chroma(self):
        """Initialise ChromaDB"""
        try:
            self.chroma_client = chromadb.PersistentClient(
                path=self.config.CHROMA_PERSIST_DIRECTORY,
                settings=Settings(allow_reset=True, anonymized_telemetry=False)
            )
            
            try:
                self.collection = self.chroma_client.get_collection("alex_documents")
            except:
                try:
                    self.collection = self.chroma_client.get_collection("alex_pro_docs")
                except:
                    self.collection = self.chroma_client.create_collection(
                        name="alex_pro_docs",
                        metadata={"description": "Documents ALEX"}
                    )
            
            # Charger la liste des fichiers d√©j√† index√©s
            self.load_indexed_files_cache()
            
        except Exception as e:
            logger.error(f"Erreur ChromaDB: {e}")
            self.collection = None
    
    def create_vector_store(self):
        """Cr√©e une nouvelle collection ChromaDB"""
        try:
            # Supprimer l'ancienne collection si elle existe
            try:
                self.chroma_client.delete_collection("alex_documents")
            except:
                pass
            
            # Cr√©er une nouvelle collection
            collection = self.chroma_client.create_collection(
                name="alex_documents",
                metadata={"hnsw:space": "cosine", "description": "Documents ALEX"}
            )
            self.collection = collection
            return collection
        except Exception as e:
            logger.error(f"Erreur cr√©ation collection: {e}")
            return self.collection
    
    def setup_watch_directory(self):
        """Configure le r√©pertoire √† surveiller"""
        self.watch_dir = Path(self.config.WATCH_DIRECTORY)
        self.watch_dir.mkdir(exist_ok=True)
        logger.info(f"   R√©pertoire surveill√©: {self.watch_dir.absolute()}")
    
    def start_file_watcher(self):
        """D√©marre la surveillance automatique du r√©pertoire"""
        try:
            if not self.watch_dir.exists():
                logger.warning(f"  R√©pertoire de surveillance introuvable: {self.watch_dir}")
                return False
                
            # Arr√™ter l'ancien observer s'il existe
            if self.observer and self.observer.is_alive():
                self.observer.stop()
                self.observer.join()
            
            # Cr√©er et d√©marrer le nouvel observer
            from watchdog.observers import Observer
            self.observer = Observer()
            handler = DocumentWatcherHandler(self)
            self.observer.schedule(handler, str(self.watch_dir), recursive=True)
            self.observer.daemon = True  # Thread daemon pour ne pas bloquer l'arr√™t
            self.observer.start()
            
            # V√©rifier que l'observer d√©marre correctement
            time.sleep(0.5)
            if self.observer.is_alive():
                logger.info(f"‚úÖ [AUTO] Surveillance automatique active: {self.watch_dir}")
                logger.info("üîç [AUTO] Les nouveaux fichiers seront index√©s automatiquement")
            else:
                logger.error(f"‚ùå [AUTO] √âchec d√©marrage surveillance: {self.watch_dir}")
                return False
            
            # Scan initial en mode intelligent (respecte le cache)
            import threading
            def initial_scan():
                try:
                    time.sleep(1)  # Petite pause pour laisser le syst√®me s'initialiser
                    logger.info("üîç [AUTO] Scan initial du r√©pertoire surveill√©...")
                    self.scan_existing_files()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [AUTO] Scan initial diff√©r√©: {e}")
            
            # Scan initial en arri√®re-plan
            scan_thread = threading.Thread(target=initial_scan, daemon=True)
            scan_thread.start()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Impossible de d√©marrer la surveillance automatique: {e}")
            logger.info("üìö Fonctionnement en mode manuel - utilisez les boutons pour indexer")
            self.observer = None
            return False
    
    def get_surveillance_status(self):
        """Obtient le statut d√©taill√© de la surveillance"""
        status = {
            'active': False,
            'observer_alive': False,
            'watch_directory': str(self.watch_dir),
            'directory_exists': self.watch_dir.exists(),
            'last_activity': getattr(self, '_last_activity', 0),
            'failed_files': len(getattr(self, '_failed_auto_files', [])),
            'failed_files_list': [Path(f).name for f in getattr(self, '_failed_auto_files', [])[:5]]
        }
        
        if self.observer:
            status['active'] = True
            status['observer_alive'] = self.observer.is_alive()
            
        return status

    # --- Response cache helpers ---
    def _make_cache_key(self, query: str, context: str) -> str:
        """Creates a normalized cache key from query + context."""
        try:
            base = (query or '').strip().lower() + '||' + (context or '')
            return hashlib.sha256(base.encode('utf-8')).hexdigest()
        except Exception:
            return str(hash((query, context)))

    def _cache_get(self, key: str):
        entry = self.response_cache.get(key)
        if not entry:
            return None
        ts, value = entry
        if time.time() - ts > self.response_cache_ttl:
            try:
                del self.response_cache[key]
            except Exception:
                pass
            return None
        # move to end (recently used)
        try:
            self.response_cache.move_to_end(key)
        except Exception:
            pass
        return value

    def _cache_set(self, key: str, value):
        try:
            self.response_cache[key] = (time.time(), value)
            self.response_cache.move_to_end(key)
            # Evict oldest if too large
            while len(self.response_cache) > self.response_cache_max:
                self.response_cache.popitem(last=False)
        except Exception:
            pass

    def _trim_context(self, context: str, per_doc_chars: int = 800, total_chars: int = 2000) -> str:
        """Trim the context to avoid sending huge prompts to the model.

        Splits on double-newlines (assumed doc boundaries), truncates each part, and stops when total
        length reaches total_chars.
        """
        if not context:
            return ""
        parts = [p.strip() for p in context.split('\n\n') if p.strip()]
        trimmed = []
        total = 0
        for p in parts:
            if total >= total_chars:
                break
            chunk = p
            if len(chunk) > per_doc_chars:
                # avoid cutting mid-word
                chunk = chunk[:per_doc_chars].rsplit(' ', 1)[0]
            if total + len(chunk) > total_chars:
                remaining = total_chars - total
                if remaining <= 0:
                    break
                chunk = chunk[:remaining]
            trimmed.append(chunk)
            total += len(chunk)
        return "\n\n".join(trimmed)
    
    def production_cleanup(self):
        """Nettoyage complet pour la production - SUPPRIME TOUT"""
        logger.info("üöÄ NETTOYAGE PRODUCTION EN COURS...")
        
        try:
            # 1. Arr√™ter la surveillance
            if self.observer and self.observer.is_alive():
                self.observer.stop()
                self.observer.join()
                logger.info("üõë Surveillance arr√™t√©e")
            
            # 2. Supprimer TOUTES les collections ChromaDB
            try:
                collections = self.chroma_client.list_collections()
                logger.info(f"üóëÔ∏è Suppression de {len(collections)} collections ChromaDB:")
                
                for collection in collections:
                    collection_name = collection.name
                    self.chroma_client.delete_collection(collection_name)
                    logger.info(f"   ‚ùå {collection_name} supprim√©e")
                
                logger.info("‚úÖ Toutes les collections ChromaDB supprim√©es")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur suppression collections: {e}")
            
            # 3. Cr√©er une nouvelle collection production vierge
            self.collection = self.chroma_client.create_collection(
                name=f"alex_production_{int(time.time())}",
                metadata={
                    "description": "ALEX Production Database - Clean Start",
                    "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "version": "production"
                }
            )
            logger.info(f"‚úÖ Nouvelle collection production cr√©√©e: {self.collection.name}")
            
            # 4. Vider compl√®tement tous les caches
            self.indexed_files.clear()
            if hasattr(self, '_failed_auto_files'):
                self._failed_auto_files.clear()
            logger.info("üßπ Caches locaux vid√©s")
            
            # 5. Red√©marrer la surveillance
            self.start_file_watcher()
            logger.info("üîÑ Surveillance red√©marr√©e")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur nettoyage production: {e}")
            return False
    
    def load_indexed_files_cache(self):
        """Charge le cache des fichiers index√©s depuis ChromaDB"""
        try:
            if self.collection:
                # R√©cup√©rer tous les documents avec leurs m√©tadonn√©es
                results = self.collection.get(include=['metadatas'])
                if results and results['metadatas']:
                    for metadata in results['metadatas']:
                        if metadata and 'file_path' in metadata and 'file_hash' in metadata:
                            self.indexed_files[metadata['file_path']] = metadata['file_hash']
                logger.info(f"üìö Cache charg√©: {len(self.indexed_files)} fichiers index√©s")
        except Exception as e:
            logger.error(f"Erreur chargement cache: {e}")
    
    def get_file_hash(self, file_path: str) -> str:
        """Calcule le hash MD5 d'un fichier"""
        try:
            with open(file_path, 'rb') as f:
                file_hash = hashlib.md5()
                for chunk in iter(lambda: f.read(4096), b""):
                    file_hash.update(chunk)
                return file_hash.hexdigest()
        except Exception as e:
            logger.error(f"Erreur calcul hash pour {file_path}: {e}")
            return ""
    
    def is_supported_file(self, file_path: str) -> bool:
        """V√©rifie si le fichier est support√© et pas temporaire"""
        file_name = Path(file_path).name
        
        # Ignorer les fichiers temporaires
        if file_name.startswith('~$') or file_name.startswith('.'):
            return False
            
        return Path(file_path).suffix.lower() in self.config.SUPPORTED_EXTENSIONS
    
    def is_file_already_indexed(self, file_path: str) -> bool:
        """V√©rifie si le fichier est d√©j√† index√© (m√™me contenu)"""
        if file_path not in self.indexed_files:
            return False
        
        current_hash = self.get_file_hash(file_path)
        stored_hash = self.indexed_files.get(file_path, "")
        
        return current_hash == stored_hash and current_hash != ""
    
    def read_file_content(self, file_path: str) -> str:
        """Lit le contenu d'un fichier"""
        try:
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.txt' or file_ext == '.md':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
            
            elif file_ext == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return json.dumps(data, indent=2, ensure_ascii=False)
            
            elif file_ext == '.csv':
                import pandas as pd
                df = pd.read_csv(file_path)
                return df.to_string()
            
            elif file_ext == '.odt':
                try:
                    # Essayer d'extraire le texte des fichiers ODT
                    import zipfile
                    import xml.etree.ElementTree as ET
                    
                    with zipfile.ZipFile(file_path, 'r') as zip_file:
                        if 'content.xml' in zip_file.namelist():
                            content_xml = zip_file.read('content.xml')
                            root = ET.fromstring(content_xml)
                            
                            # Extraire tout le texte
                            text_content = []
                            for elem in root.iter():
                                if elem.text:
                                    text_content.append(elem.text.strip())
                                if elem.tail:
                                    text_content.append(elem.tail.strip())
                            
                            return ' '.join(filter(None, text_content))
                    return ""
                except Exception as odt_error:
                    logger.warning(f"Erreur lecture ODT {file_path}: {odt_error}")
                    return ""
            
            elif file_ext == '.pdf':
                try:
                    # Extraction PDF avec PyPDF2 ou pdfplumber
                    try:
                        import PyPDF2
                        with open(file_path, 'rb') as pdf_file:
                            pdf_reader = PyPDF2.PdfReader(pdf_file)
                            text_content = []
                            for page in pdf_reader.pages:
                                text_content.append(page.extract_text())
                            return '\n'.join(text_content)
                    except ImportError:
                        try:
                            import pdfplumber
                            with pdfplumber.open(file_path) as pdf:
                                text_content = []
                                for page in pdf.pages:
                                    text_content.append(page.extract_text() or '')
                                return '\n'.join(text_content)
                        except ImportError:
                            logger.warning(f"üìÑ PyPDF2 et pdfplumber non install√©s pour: {file_path}")
                            return f"Fichier PDF d√©tect√©: {Path(file_path).name} - Contenu non extractible"
                except Exception as pdf_error:
                    logger.error(f"Erreur extraction PDF {file_path}: {pdf_error}")
                    # Retourner au moins les m√©tadonn√©es du fichier
                    return f"Document PDF: {Path(file_path).name} - Fichier d√©tect√© mais extraction √©chou√©e. Contient probablement des informations d'Accel Tech."
            
            elif file_ext == '.docx':
                try:
                    import docx
                    doc = docx.Document(file_path)
                    text_content = []
                    for paragraph in doc.paragraphs:
                        text_content.append(paragraph.text)
                    return '\n'.join(text_content)
                except ImportError:
                    logger.warning(f"üìÑ python-docx non install√© pour: {file_path}")
                    return f"Fichier DOCX d√©tect√©: {Path(file_path).name} - Contenu non extractible"
                except Exception as docx_error:
                    logger.error(f"Erreur extraction DOCX {file_path}: {docx_error}")
                    return f"Fichier DOCX: {Path(file_path).name}"
            
            # Pour d'autres types de fichiers, essayer la lecture basique
            else:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
                    
        except Exception as e:
            logger.error(f"Erreur lecture fichier {file_path}: {e}")
            return ""
    
    def process_new_file(self, file_path: str):
        """Traite un nouveau fichier"""
        if not self.is_supported_file(file_path):
            logger.info(f"‚è≠Ô∏è Type de fichier non support√©: {file_path}")
            return
        
        if self.is_file_already_indexed(file_path):
            logger.info(f"‚úÖ Fichier d√©j√† index√©: {Path(file_path).name}")
            return
        
        self.index_file(file_path)
    
    def process_new_file_background(self, file_path: str):
        """Traite un nouveau fichier en arri√®re-plan (ne bloque pas le chatbot)"""
        try:
            self._last_activity = time.time()  # Mettre √† jour l'activit√©
            
            if not self.is_supported_file(file_path):
                logger.debug(f"‚è≠Ô∏è [AUTO] Format non support√©: {Path(file_path).name}")
                return
            
            if self.is_file_already_indexed(file_path):
                logger.debug(f"‚è≠Ô∏è [AUTO] Fichier d√©j√† index√©: {Path(file_path).name}")
                return
            
            logger.info(f"üîÑ [AUTO] Indexation en arri√®re-plan: {Path(file_path).name}")
            self.index_file(file_path)
            
            # V√©rifier que l'indexation a r√©ussi
            if self.is_file_already_indexed(file_path):
                logger.info(f"‚úÖ [AUTO] Indexation confirm√©e: {Path(file_path).name}")
                # Retirer de la liste des √©checs si pr√©sent
                if file_path in self._failed_auto_files:
                    self._failed_auto_files.remove(file_path)
            else:
                logger.warning(f"‚ö†Ô∏è [AUTO] Indexation √©chou√©e pour: {Path(file_path).name}")
                if file_path not in self._failed_auto_files:
                    self._failed_auto_files.append(file_path)
            
        except Exception as e:
            logger.error(f"‚ùå [AUTO] Erreur traitement nouveau fichier {file_path}: {e}")
            if file_path not in self._failed_auto_files:
                self._failed_auto_files.append(file_path)
    
    def process_modified_file_background(self, file_path: str):
        """Traite un fichier modifi√© en arri√®re-plan"""
        try:
            if not self.is_supported_file(file_path):
                return
            
            current_hash = self.get_file_hash(file_path)
            stored_hash = self.indexed_files.get(file_path, "")
            
            if current_hash != stored_hash:
                logger.info(f"üîÑ [AUTO] R√©indexation automatique: {Path(file_path).name}")
                # Supprimer l'ancienne version
                self.remove_file_from_index(file_path)
                # R√©indexer
                self.index_file(file_path)
            else:
                logger.debug(f"‚è≠Ô∏è [AUTO] Fichier inchang√©: {Path(file_path).name}")
                
        except Exception as e:
            logger.error(f"  [AUTO] Erreur traitement fichier modifi√© {file_path}: {e}")
    
    def process_modified_file(self, file_path: str):
        """Traite un fichier modifi√© (version manuelle)"""
        if not self.is_supported_file(file_path):
            return
        
        current_hash = self.get_file_hash(file_path)
        stored_hash = self.indexed_files.get(file_path, "")
        
        if current_hash != stored_hash:
            logger.info(f"üîÑ R√©indexation du fichier modifi√©: {Path(file_path).name}")
            # Supprimer l'ancienne version
            self.remove_file_from_index(file_path)
            # R√©indexer
            self.index_file(file_path)
    
    def index_file(self, file_path: str):
        """Indexe un fichier dans ChromaDB avec optimisations"""
        try:
            content = self.read_file_content(file_path)
            if not content.strip():
                logger.warning(f"  Fichier vide: {file_path}")
                return
            
            # D√©couper le contenu en chunks plus grands
            chunks = self.chunk_text(content)
            if not chunks:
                return
            
            logger.info(f"üîÑ Indexation de {Path(file_path).name} ({len(chunks)} chunks)")
            
            # G√©n√©rer les embeddings en parall√®le (limit√©) et avec cache
            embeddings = []
            valid_chunks = []

            # Limit number of threads to avoid saturating Ollama API
            max_workers = min(4, len(chunks)) if len(chunks) > 0 else 1
            from concurrent.futures import ThreadPoolExecutor, as_completed

            futures = {}
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                for idx, chunk in enumerate(chunks):
                    # Check cache first
                    key = hashlib.sha256(chunk.encode('utf-8')).hexdigest()
                    if key in self.embedding_cache:
                        emb = self.embedding_cache[key]
                        if emb:
                            embeddings.append(emb)
                            valid_chunks.append(chunk)
                        continue

                    futures[executor.submit(self.generate_embeddings, chunk)] = (idx, chunk, key)

                for fut in as_completed(futures):
                    idx, chunk, key = futures[fut]
                    try:
                        emb = fut.result()
                        if emb:
                            embeddings.append(emb)
                            valid_chunks.append(chunk)
                            # Cache the embedding
                            try:
                                self.embedding_cache[key] = emb
                            except Exception:
                                pass
                    except Exception as e:
                        logger.warning(f"  Embedding failed for chunk {idx} of {file_path}: {e}")
            
            if not embeddings:
                logger.error(f"  Impossible de g√©n√©rer les embeddings pour: {file_path}")
                return
            
            # Ajouter √† ChromaDB
            file_hash = self.get_file_hash(file_path)
            file_name = Path(file_path).name
            
            ids = [f"{file_name}_{i}_{file_hash[:8]}" for i in range(len(valid_chunks))]
            metadatas = [
                {
                    "file_path": file_path,
                    "file_name": file_name,
                    "file_hash": file_hash,
                    "chunk_index": i,
                    "indexed_at": time.strftime("%Y-%m-%d %H:%M:%S")
                }
                for i in range(len(valid_chunks))
            ]
            
            self.collection.add(
                embeddings=embeddings,
                documents=valid_chunks,
                metadatas=metadatas,
                ids=ids
            )
            
            # Mettre √† jour le cache
            self.indexed_files[file_path] = file_hash
            
            logger.info(f"‚úÖ Fichier index√©: {file_name} ({len(valid_chunks)} chunks)")
            
        except Exception as e:
            logger.error(f"  Erreur indexation {file_path}: {e}")
    
    def remove_file_from_index(self, file_path: str):
        """Supprime un fichier de l'index"""
        try:
            # Trouver tous les documents de ce fichier
            results = self.collection.get(
                where={"file_path": file_path},
                include=['metadatas']
            )
            
            if results and results['ids']:
                self.collection.delete(ids=results['ids'])
                logger.info(f"üóëÔ∏è Ancien index supprim√© pour: {Path(file_path).name}")
                
        except Exception as e:
            logger.error(f"Erreur suppression index: {e}")
    
    def chunk_text(self, text: str, chunk_size: int = 1500, overlap: int = 100) -> List[str]:
        """D√©coupe le texte en chunks plus grands pour optimiser l'indexation"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = min(start + chunk_size, len(text))
            
            # Essayer de couper √† un point naturel (phrase)
            if end < len(text):
                # Chercher le dernier point ou saut de ligne
                last_sentence = max(
                    text.rfind('.', start, end),
                    text.rfind('\n', start, end),
                    text.rfind('!', start, end),
                    text.rfind('?', start, end)
                )
                
                if last_sentence > start + 200:  # Au moins 200 caract√®res
                    end = last_sentence + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap if end < len(text) else end
        
        return chunks
    
    def scan_existing_files(self):
        """Scanne les fichiers existants au d√©marrage avec optimisations"""
        logger.info("ÔøΩ Scan optimis√© des fichiers existants...")
        
        try:
            import concurrent.futures
            
            # Collecter tous les fichiers et classifier
            files_to_index = []
            already_indexed = []
            
            for file_path in self.watch_dir.rglob('*'):
                if file_path.is_file() and self.is_supported_file(str(file_path)):
                    if self.is_file_already_indexed(str(file_path)):
                        already_indexed.append(str(file_path))
                    else:
                        files_to_index.append(str(file_path))
            
            # Afficher le statut
            if already_indexed:
                logger.info(f"‚è≠Ô∏è {len(already_indexed)} fichiers d√©j√† index√©s (ignor√©s):")
                for file_path in already_indexed:
                    logger.info(f"   ‚è≠Ô∏è {Path(file_path).name}")
            
            if not files_to_index:
                logger.info("‚úÖ Tous les fichiers sont d√©j√† index√©s - Aucun nouveau fichier √† traiter")
                return
            
            logger.info(f"üìö Indexation de {len(files_to_index)} fichiers en parall√®le...")
            
            # Traitement parall√®le avec ThreadPoolExecutor
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                # Soumettre tous les fichiers pour traitement
                future_to_file = {
                    executor.submit(self.index_file, file_path): file_path 
                    for file_path in files_to_index
                }
                
                # Collecter les r√©sultats
                count = 0
                for future in concurrent.futures.as_completed(future_to_file):
                    file_path = future_to_file[future]
                    try:
                        future.result()
                        count += 1
                        if count % 5 == 0:  # Progress indicator
                            logger.info(f"‚è≥ {count}/{len(files_to_index)} fichiers trait√©s...")
                    except Exception as e:
                        logger.error(f"  Erreur avec {file_path}: {e}")
            
            logger.info(f"üéØ {count} fichiers index√©s avec succ√®s!")
            
        except Exception as e:
            logger.warning(f"  Erreur lors du scan initial: {e}")
            logger.info("üìö Fallback: indexation s√©quentielle")
            # Fallback vers m√©thode s√©quentielle
            count = 0
            for file_path in self.watch_dir.rglob('*'):
                if file_path.is_file() and self.is_supported_file(str(file_path)):
                    if not self.is_file_already_indexed(str(file_path)):
                        self.index_file(str(file_path))
                        count += 1

    def generate_embeddings(self, text: str, max_retries: int = 2) -> List[float]:
        """G√©n√®re des embeddings avec Ollama (nomic-embed-text)"""
        for attempt in range(max_retries + 1):
            try:
                payload = {
                    "model": self.config.OLLAMA_EMBEDDING_MODEL,
                    "prompt": text
                }

                # Timeout r√©duit et session r√©utilisable
                if not hasattr(self, '_session'):
                    self._session = requests.Session()
                    self._session.headers.update({'Connection': 'keep-alive'})
                    self._session.verify = False  # D√©sactiver la v√©rification SSL pour Ollama

                # Timeout progressif selon l'essai
                timeout = 30 + (attempt * 15)  # 30s, 45s, 60s
                logger.info(f"üîÑ Tentative {attempt + 1}/{max_retries + 1} embedding Ollama (timeout: {timeout}s)")

                response = self._session.post(
                    f"{self.config.OLLAMA_BASE_URL}/api/embeddings",
                    json=payload,
                    timeout=timeout,
                    verify=False  # D√©sactiver la v√©rification SSL du certificat expir√©
                )

                if response.status_code == 200:
                    logger.info(f"‚úÖ Embedding g√©n√©r√© avec succ√®s (tentative {attempt + 1})")
                    return response.json()['embedding']
                else:
                    logger.warning(f"‚ö†Ô∏è R√©ponse HTTP {response.status_code} (tentative {attempt + 1})")

            except requests.exceptions.Timeout as e:
                logger.warning(f"‚è±Ô∏è Timeout tentative {attempt + 1}/{max_retries + 1}: {e}")
                if attempt < max_retries:
                    time.sleep(2)  # Pause avant retry
                    continue
            except Exception as e:
                logger.error(f"‚ùå Erreur embedding (tentative {attempt + 1}): {e}")
                if attempt < max_retries:
                    time.sleep(2)
                    continue

        logger.error(f"üí• √âchec g√©n√©ration embedding apr√®s {max_retries + 1} tentatives")
        return []
    
    def search_context(self, query: str, limit: int = 5) -> str:
        """Recherche le contexte dans les documents index√©s"""
        if not self.collection:
            logger.warning("  Aucune collection ChromaDB disponible")
            return ""
        
        try:
            # G√©n√©rer embedding de la requ√™te
            query_embedding = self.generate_embeddings(query)
            if not query_embedding:
                logger.warning("  Impossible de g√©n√©rer embedding pour la requ√™te")
                return ""
            
            # Rechercher dans ChromaDB
            logger.info(f"üîç Recherche dans ChromaDB: {query[:50]}...")
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=limit,
                include=['documents', 'metadatas']
            )
            
            if results and results['documents'] and results['documents'][0]:
                documents = results['documents'][0]
                metadatas = results['metadatas'][0] if results['metadatas'] else []
                
                # Construire le contexte avec sources
                context_parts = []
                for i, doc in enumerate(documents):
                    source = ""
                    if metadatas and i < len(metadatas) and metadatas[i]:
                        source_path = metadatas[i].get('source', '')
                        if source_path:
                            source = f"[Source: {Path(source_path).name}]"
                    
                    context_parts.append(f"{source}\n{doc}")
                
                logger.info(f"‚úÖ Contexte trouv√©: {len(documents)} documents")
                return "\n\n".join(context_parts)
            else:
                logger.warning("  Aucun contexte trouv√© dans ChromaDB")
                return ""
        except Exception as e:
            logger.error(f"  Erreur recherche ChromaDB: {e}")
            return ""
    
    def is_greeting_or_general(self, message: str) -> bool:
        """D√©tecte si le message est une salutation ou question g√©n√©rale SIMPLE"""
        message_lower = message.lower().strip()
        
        # Debug: log du message pour voir ce qui se passe
        logger.info(f"üîç Analyse message salutation: '{message_lower}'")
        
        # LOGIQUE SIMPLIFI√âE : detecter seulement les vraies salutations courtes
        
        # Salutations simples EXACTES (messages complets)
        exact_greetings = [
            'salut', 'bonjour', 'bonsoir', 'hello', 'hi', 'hey', 'coucou',
            '√ßa va', 'comment √ßa va', 'comment allez-vous',
            'qui es-tu', 'pr√©sente-toi', 'aide', 'help'
        ]
        
        # V√©rifier si le message EST exactement une salutation (avec tol√©rance pour la ponctuation)
        clean_message = message_lower.replace('?', '').replace('!', '').replace('.', '').strip()
        
        if clean_message in exact_greetings:
            logger.info(f"‚úÖ Salutation exacte d√©tect√©e: '{clean_message}'")
            return True
        
        # V√©rifier les salutations tr√®s courtes (maximum 3 mots)
        if len(message_lower.split()) <= 3:
            for greeting in ['salut', 'bonjour', 'hello', 'hi', 'hey']:
                if greeting in message_lower:
                    logger.info(f"‚úÖ Salutation courte d√©tect√©e: '{greeting}'")
                    return True
        
        logger.info(f"‚ùå Pas de salutation d√©tect√©e pour: '{message_lower}'")
        return False
    
    def generate_greeting_response(self, message: str) -> str:
        """G√©n√®re une r√©ponse appropri√©e pour les salutations et questions g√©n√©rales"""
        message_lower = message.lower().strip()
        
        # R√©ponses aux salutations avec "comment allez-vous" ou similaire
        if any(pattern in message_lower for pattern in ['comment allez', 'comment √ßa va', '√ßa va']):
            return """Bonjour ! Je vais tr√®s bien, merci ! Je suis ALEX, votre assistant IA d'Accel Tech.

Je suis l√† pour vous aider √† explorer et analyser vos documents de fa√ßon conversationnelle.

Comment m'utiliser :
‚Ä¢ Posez-moi des questions sur le contenu de vos documents
‚Ä¢ Je peux analyser, r√©sumer et extraire des informations
‚Ä¢ J'ai acc√®s aux documents dans votre dossier surveill√©

Exemples de questions :
‚Ä¢ "Quels sont les services d'Accel Tech ?"
‚Ä¢ "R√©sume-moi la mission d'Accel Tech"
‚Ä¢ "Quelles sont les valeurs de l'entreprise ?"

Et vous, comment puis-je vous aider aujourd'hui ?"""
        
        # R√©ponses aux salutations simples
        elif any(greeting in message_lower for greeting in ['salut', 'bonjour', 'hello', 'hi', 'hey', 'coucou']):
            return """Salut ! Je suis ALEX, votre assistant IA d'Accel Tech !

Je suis l√† pour vous aider √† explorer et analyser vos documents de fa√ßon conversationnelle.

Comment m'utiliser :
‚Ä¢ Posez-moi des questions sur le contenu de vos documents
‚Ä¢ Je peux analyser, r√©sumer et extraire des informations
‚Ä¢ J'ai acc√®s aux documents dans votre dossier surveill√©

Exemples de questions :
‚Ä¢ "Quels sont les services d'Accel Tech ?"
‚Ä¢ "R√©sume-moi la mission d'Accel Tech"
‚Ä¢ "Quelles sont les valeurs de l'entreprise ?"

N'h√©sitez pas √† me poser vos questions !"""

        # Questions sur ALEX
        elif any(q in message_lower for q in ['qui es-tu', 'pr√©sente-toi', 'tu es qui']):
            return """Je suis ALEX (Assistant Learning and eXpert)

D√©velopp√© par Accel Tech, je suis un assistant IA sp√©cialis√© dans l'analyse de documents avec la technologie RAG (Retrieval-Augmented Generation).

Mes capacit√©s :
‚Ä¢ Analyse et recherche dans vos documents PDF, DOCX, TXT, ODT
‚Ä¢ R√©ponses contextuelles bas√©es sur vos fichiers
‚Ä¢ Surveillance automatique des nouveaux documents
‚Ä¢ Interface moderne et intuitive

Ma technologie :
‚Ä¢ Mod√®le Mistral 7B pour la g√©n√©ration de r√©ponses
‚Ä¢ ChromaDB pour la recherche vectorielle
‚Ä¢ Embeddings Nomic pour la compr√©hension s√©mantique

Posez-moi des questions sp√©cifiques sur vos documents !"""

        # Questions d'aide
        elif any(q in message_lower for q in ['aide', 'help', 'comment']):
            return """Guide d'utilisation d'ALEX

Comment poser des questions :
‚Ä¢ Soyez sp√©cifique : "Quels sont les services d'Accel Tech ?"
‚Ä¢ Utilisez des mots-cl√©s pertinents de vos documents
‚Ä¢ Demandez des analyses : "R√©sume la pr√©sentation..."

Types de recherches possibles :
‚Ä¢ Recherche d'informations pr√©cises
‚Ä¢ R√©sum√©s de documents ou sections
‚Ä¢ Comparaisons entre diff√©rents documents
‚Ä¢ Extraction de donn√©es chiffr√©es

Astuces pour de meilleures r√©ponses :
‚Ä¢ Utilisez le vocabulaire de vos domaines (finance, juridique, etc.)
‚Ä¢ Posez des questions ouvertes pour plus de d√©tails
‚Ä¢ Pr√©cisez le document si vous en cherchez un en particulier

Essayez maintenant avec une question sur vos documents !"""

        # R√©ponse par d√©faut
        else:
            return """Salut ! Je suis ALEX, votre assistant IA personnel.

Posez-moi des questions sur vos documents et je vous aiderai √† trouver les informations que vous cherchez !

Exemple: "Quels sont les principaux points abord√©s dans mes documents ?" """

    def generate_natural_greeting_response(self, message: str) -> str:
        """G√©n√®re une r√©ponse naturelle aux salutations en utilisant Mistral directement"""
        try:
            # Prompt pour que Mistral r√©ponde naturellement aux salutations
            greeting_prompt = f"""Tu es ALEX, un assistant chatbot d'Accel Tech.

L'utilisateur te dit: "{message}"

IMPORTANT: Tu es un chatbot sp√©cialis√© d'Accel Tech et tu ne r√©ponds QUE aux questions li√©es √† Accel Tech et ses services.

R√©ponds de fa√ßon naturelle et professionnelle:
- Pr√©sente-toi comme ALEX, le chatbot assistant d'Accel Tech
- Pr√©cise que tu r√©ponds uniquement aux questions concernant Accel Tech
- Mentionne bri√®vement les services d'Accel Tech (modernisation, innovation, consulting)
- Reste professionnel et concis (maximum 3-4 lignes)
- Invite l'utilisateur √† poser des questions sur Accel Tech

R√©ponse:"""

            if not self.nvidia_client:
                return self.generate_greeting_response(message)

            # Utiliser l'API NVIDIA avec streaming
            completion = self.nvidia_client.chat.completions.create(
                model=self.config.NVIDIA_CHAT_MODEL,
                messages=[{"role": "user", "content": greeting_prompt}],
                temperature=0.7,
                top_p=0.9,
                max_tokens=200,
                stream=False
            )

            if completion.choices and len(completion.choices) > 0:
                natural_response = completion.choices[0].message.content
                logger.info(f"ü§ñ R√©ponse naturelle de salutation g√©n√©r√©e")
                return natural_response.strip()
            else:
                # Fallback vers r√©ponse pr√©d√©finie
                return self.generate_greeting_response(message)
                
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©ponse naturelle: {e}")
            # Fallback vers r√©ponse pr√©d√©finie
            return self.generate_greeting_response(message)

    def chat(self, message: str) -> str:
        """G√©n√®re une r√©ponse de chat bas√©e UNIQUEMENT sur les documents index√©s"""
        try:
            # Rechercher le contexte dans les documents index√©s
            context = self.search_context(message, limit=5)
            
            # V√©rifier si le contexte est pertinent pour la question
            if context and context.strip():
                message_lower = message.lower()
                
                # Mots-cl√©s EXPLICITES d'Accel Tech qui doivent √™tre dans la QUESTION
                accel_explicit_keywords = [
                    'accel', 'accel tech', 'entreprise', 'soci√©t√©', 'services', 
                    'solutions', 'consulting', 'technologie', 'digital', 'transformation',
                    'machine learning', 'data science', 'ia', 'ai', 'innovation',
                    'modernisation', 'expertise', 'domaines', 'accompagnement'
                ]
                
                # V√©rifier si la question contient explicitement des r√©f√©rences √† Accel Tech ou ses services
                has_accel_in_question = any(keyword in message_lower for keyword in accel_explicit_keywords)
                
                # V√©rifier UNIQUEMENT si la question contient des mots-cl√©s Accel Tech explicites
                # Plus de tol√©rance pour les questions g√©n√©riques - elles doivent √™tre TR√àS sp√©cifiques
                
                # Questions tr√®s sp√©cifiques sur l'entreprise (qui ne peuvent concerner qu'Accel Tech)
                specific_business_questions = [
                    'qui √™tes-vous', 'qui es-tu', 'pr√©sente-toi', 'pr√©sentation',
                    'votre entreprise', 'votre soci√©t√©', 'votre mission', 'vos services',
                    'vos solutions', 'votre √©quipe', 'contact', 'adresse'
                ]
                
                # V√©rifier si c'est une question tr√®s sp√©cifique sur l'entreprise
                is_specific_business_question = any(q in message_lower for q in specific_business_questions)
                
                # Nouvelle logique STRICTE : accepter SEULEMENT si :
                # 1. La question contient explicitement des mots-cl√©s Accel Tech
                # 2. OU c'est une question tr√®s sp√©cifique sur l'entreprise ET le contexte parle d'Accel Tech
                context_has_accel = 'accel' in context.lower() and 'tech' in context.lower()
                
                if has_accel_in_question or (is_specific_business_question and context_has_accel):
                    # Question li√©e √† Accel Tech - r√©pondre avec le contexte
                    prompt = f"""INSTRUCTION ABSOLUE: Tu DOIS r√©pondre UNIQUEMENT en utilisant les informations du CONTEXTE ci-dessous.

CONTEXTE DES DOCUMENTS:
{context}

QUESTION: {message}

R√àGLES DE FORMATAGE STRICTES:
- N'utilise JAMAIS de formatage Markdown (**, *, _, etc.)
- Utilise uniquement du texte plain
- OBLIGATOIRE: Pour les listes num√©rot√©es, S√âPARE chaque √©l√©ment par un RETOUR √Ä LA LIGNE

EXEMPLE CORRECT de liste num√©rot√©e:
1. Fourniture de solutions compl√®tes et sur mesure dans de nombreux domaines de la technologie de l'information

2. Accompagnement de bout en bout

3. Excellence technique garantie

4. Innovation constante

JAMAIS comme cela: "1. Premier 2. Deuxi√®me 3. Troisi√®me"
- Pour les listes √† puces: utilise des tirets simples (-) avec retour √† la ligne entre chaque √©l√©ment
- Pas de caract√®res sp√©ciaux de formatage
- Chaque √©l√©ment de liste DOIT √™tre sur sa propre ligne

R√âPONSE: Basez votre r√©ponse EXCLUSIVEMENT sur le contexte ci-dessus. R√©pondez en texte plain sans formatage."""
                    
                    # Debug: Logger le prompt et le contexte
                    logger.info(f"   PROMPT ENVOY√â √Ä NVIDIA:")
                    logger.info(f"Contexte: {context[:200]}..." if context else "AUCUN CONTEXTE!")
                    logger.info(f"Prompt: {prompt[:300]}...")

                    # Trim context before generating to reduce prompt size
                    trimmed_context = self._trim_context(context, per_doc_chars=800, total_chars=2000)

                    # Cache check
                    cache_key = self._make_cache_key(message, trimmed_context)
                    cached = self._cache_get(cache_key)
                    if cached:
                        logger.info("‚ôªÔ∏è R√©ponse servie depuis le cache")
                        return cached

                    # Replace the context in the prompt with the trimmed version
                    prompt = prompt.replace(context, trimmed_context)

                    if not self.nvidia_client:
                        return "D√©sol√©, je rencontre un probl√®me technique. Veuillez r√©essayer."

                    # Utiliser l'API NVIDIA
                    completion = self.nvidia_client.chat.completions.create(
                        model=self.config.NVIDIA_CHAT_MODEL,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.2,
                        top_p=0.7,
                        max_tokens=1024,
                        stream=False
                    )

                    if completion.choices and len(completion.choices) > 0:
                        nvidia_response = completion.choices[0].message.content
                        logger.info(f"   R√âPONSE NVIDIA: {str(nvidia_response)[:200]}...")

                        # Post-traitement pour forcer le bon formatage des listes
                        formatted_response = self.format_lists(nvidia_response)

                        # Cache the result
                        try:
                            self._cache_set(cache_key, formatted_response)
                        except Exception:
                            pass

                        return formatted_response
                    else:
                        return "D√©sol√©, je rencontre un probl√®me technique. Veuillez r√©essayer."
                else:
                    # Question non li√©e √† Accel Tech
                    logger.info(f"üö´ Question rejet√©e (non-Accel Tech): {message}")
                    return "Je suis ALEX, assistant IA d'Accel Tech. Je ne peux r√©pondre qu'aux questions concernant Accel Tech et ses services."
            else:
                # Aucun contexte trouv√© - r√©ponse standard
                logger.info(f"üö´ Aucun contexte trouv√© pour: {message}")
                return "Je suis ALEX, assistant IA d'Accel Tech. Je ne peux r√©pondre qu'aux questions concernant Accel Tech et ses services."
            
        except Exception as e:
            logger.error(f"Erreur chat: {e}")
            return "Une erreur s'est produite. Veuillez r√©essayer dans un moment."
    
    def format_lists(self, text):
        """Post-traite le texte pour forcer le bon formatage des listes num√©rot√©es"""
        import re
        
        # Approche plus simple et efficace - diviser et reconstruire
        # Pattern pour d√©tecter les num√©ros coll√©s: "1. texte 2. texte"
        
        # √âtape 1: Ins√©rer des retours √† la ligne avant chaque num√©ro qui suit du texte
        # Pattern am√©lior√© qui capture mieux les cas r√©els
        formatted_text = text
        
        # Remplacer tous les patterns "texte 2." par "texte\n\n2."
        pattern1 = r'([a-zA-Z√†-√ø\.\,\!\?\:\;]+)\s+(\d+\.)'
        formatted_text = re.sub(pattern1, r'\1\n\n\2', formatted_text)
        
        # Remplacer les patterns ": 2." par ":\n\n2."
        pattern2 = r'([\:\.\!])\s+(\d+\.)'  
        formatted_text = re.sub(pattern2, r'\1\n\n\2', formatted_text)
        
        # Remplacer les patterns ") 2." par ")\n\n2."
        pattern3 = r'([\)])\s+(\d+\.)'
        formatted_text = re.sub(pattern3, r'\1\n\n\2', formatted_text)
        
        # √âtape 2: Nettoyer les multiples retours √† la ligne
        formatted_text = re.sub(r'\n{3,}', '\n\n', formatted_text)
        
        # √âtape 3: S'assurer que chaque ligne num√©rot√©e est suivie d'une ligne vide
        lines = formatted_text.split('\n')
        result_lines = []
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            result_lines.append(lines[i])  # Garder l'indentation originale
            
            # Si c'est une ligne num√©rot√©e (commence par un chiffre suivi d'un point)
            if re.match(r'^\d+\.', line):
                # V√©rifier si la prochaine ligne n'est pas vide et n'est pas un autre num√©ro
                if (i + 1 < len(lines) and 
                    lines[i + 1].strip() != '' and 
                    not re.match(r'^\d+\.', lines[i + 1].strip())):
                    # Ne rien faire, laisser le texte continuer
                    pass
                elif (i + 1 < len(lines) and 
                      re.match(r'^\d+\.', lines[i + 1].strip())):
                    # La prochaine ligne est aussi num√©rot√©e, ajouter une ligne vide
                    result_lines.append('')
                elif (i + 1 < len(lines) and 
                      lines[i + 1].strip() == '' and
                      i + 2 < len(lines) and
                      re.match(r'^\d+\.', lines[i + 2].strip())):
                    # Il y a d√©j√† une ligne vide, c'est bon
                    pass
            
            i += 1
        
        return '\n'.join(result_lines)

# Template HTML ultra moderne et responsif avec effets
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>   ALEX - Assistant IA Professionnel</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: #f5f7fa;
            margin: 0;
            padding: 0;
            position: relative;
        }



        /* Bouton flottant d'ouverture */
        .chat-toggle-btn {
            position: fixed;
            bottom: 80px;
            right: 20px;
            width: 60px;
            height: 60px;
            background: linear-gradient(135deg, #1e3a8a 0%, #2563eb 50%, #1e40af 100%);
            border: none;
            border-radius: 50%;
            color: white;
            font-size: 24px;
            cursor: pointer;
            box-shadow: 0 4px 20px rgba(30, 58, 138, 0.3);
            z-index: 1000;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .chat-toggle-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 8px 30px rgba(30, 58, 138, 0.4);
        }

        .chat-toggle-btn.active {
            background: linear-gradient(135deg, #e74c3c, #c0392b);
        }

        /* Container de chat en widget */
        .chat-widget {
            position: fixed;
            bottom: 150px;
            right: 20px;
            width: 380px;
            height: 600px;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
            z-index: 999;
            display: none;
            flex-direction: column;
            overflow: hidden;
            border: 1px solid rgba(30, 58, 138, 0.1);
            animation: slideIn 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(30px) scale(0.9);
            }
            to {
                opacity: 1;
                transform: translateY(0) scale(1);
            }
        }

        .chat-widget.open {
            display: flex;
        }

        .container {
            display: flex;
            flex-direction: column;
            height: 100%;
            padding: 0;
            margin: 0;
            width: 100%;
            max-width: none;
            background: transparent;
            border-radius: 0;
            box-shadow: none;
            animation: none;
        }



        .chat-header {
            background: linear-gradient(135deg, #1e3a8a 0%, #2563eb 50%, #1e40af 100%);
            color: white;
            padding: 20px;
            text-align: center;
            border-radius: 20px 20px 0 0;
            position: relative;
        }

        .chat-header h1 {
            margin: 0;
            font-size: 1.5em;
            font-weight: 600;
        }

        .chat-header p {
            margin: 5px 0 0 0;
            font-size: 0.9em;
            opacity: 0.9;
        }

        .close-chat-btn {
            position: absolute;
            top: 15px;
            right: 15px;
            background: none;
            border: none;
            color: white;
            font-size: 20px;
            cursor: pointer;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }

        .close-chat-btn:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: rotate(90deg);
        }

        .chat-container {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            background: #f8f9fa;
            border-radius: 0;
            border: none;
            box-shadow: none;
            margin: 0;
        }



        /* Scrollbar personnalis√©e */
        .chat-container::-webkit-scrollbar {
            width: 8px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: linear-gradient(135deg, #1e3a8a, #3b82f6);
            border-radius: 4px;
            transition: all 0.3s ease;
        }

        .chat-container::-webkit-scrollbar-thumb:hover {
            background: linear-gradient(135deg, #1e40af, #2563eb);
        }

        .message {
            margin-bottom: 20px;
            padding: 18px 24px;
            border-radius: 18px;
            animation: messageSlideIn 0.6s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
        }

        .message:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
        }

        @keyframes messageSlideIn {
            from {
                opacity: 0;
                transform: translateY(30px) scale(0.95);
            }
            to {
                opacity: 1;
                transform: translateY(0) scale(1);
            }
        }

        .user-message {
            background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);
            color: white;
            margin-left: 20%;
            text-align: right;
            box-shadow: 0 2px 10px rgba(30, 58, 138, 0.2);
            border: none;
        }

        .user-message::after {
            display: none;
        }

        .assistant-message {
            background: white;
            margin-right: 20%;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            color: #333;
            border: 1px solid #e9ecef;
        }

        .assistant-message::after {
            display: none;
        }

        .chat-input-section {
            padding: 20px;
            background: white;
            border-top: 1px solid #e9ecef;
            border-radius: 0 0 20px 20px;
        }

        .input-section {
            display: flex;
            gap: 10px;
            margin: 0;
        }

        .input-wrapper {
            flex: 1;
            position: relative;
        }

        #messageInput {
            flex: 1;
            padding: 12px 16px;
            border: 2px solid #e9ecef;
            border-radius: 25px;
            font-size: 14px;
            color: #333;
            outline: none;
            transition: border-color 0.3s ease;
        }

        #messageInput::placeholder {
            color: #6c757d;
        }

        #messageInput:focus {
            border-color: #2563eb;
        }



        .send-btn {
            background: linear-gradient(135deg, #1e3a8a 0%, #2563eb 50%, #1e40af 100%);
            color: white;
            border: none;
            padding: 12px 20px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            transition: all 0.3s ease;
            min-width: 80px;
        }

        .send-btn:hover {
            transform: translateY(-1px);
            box-shadow: 0 4px 12px rgba(30, 58, 138, 0.3);
        }

        .send-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }



        .loading {
            display: none;
            text-align: center;
            color: rgba(255, 255, 255, 0.9);
            font-style: italic;
            font-weight: 500;
            margin: 15px 0;
            animation: loadingPulse 2s ease-in-out infinite;
        }

        @keyframes loadingPulse {
            0%, 100% { opacity: 0.6; }
            50% { opacity: 1; }
        }

        .typing {
            display: inline-block;
            width: 24px;
            height: 24px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: rgba(255, 255, 255, 0.9);
            animation: spin 1s linear infinite;
            margin-right: 10px;
            vertical-align: middle;
        }

        .loading-dots {
            display: inline-block;
            margin-left: 10px;
        }

        .loading-dots::after {
            content: '';
            animation: dots 1.5s steps(4, end) infinite;
        }

        @keyframes dots {
            0%, 20% { content: '.'; }
            40% { content: '..'; }
            60%, 100% { content: '...'; }
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }



        /* Responsive Design */
        @media (max-width: 768px) {
            .chat-widget {
                width: 95%;
                height: 70vh;
                right: 2.5%;
                left: 2.5%;
                bottom: 140px;
            }
            
            .chat-toggle-btn {
                width: 55px;
                height: 55px;
                font-size: 22px;
                bottom: 60px;
            }
            
            .input-section {
                flex-direction: column;
                gap: 10px;
            }
            
            .send-btn {
                width: 100%;
            }
            
            .message {
                margin-left: 5% !important;
                margin-right: 5% !important;
            }
        }

        @media (max-width: 480px) {
            .chat-widget {
                width: 100%;
                height: 100vh;
                right: 0;
                left: 0;
                bottom: 0;
                border-radius: 0;
            }
            
            .chat-header {
                border-radius: 0;
            }
            
            .chat-input-section {
                border-radius: 0;
            }
            
            .message {
                margin-left: 0 !important;
                margin-right: 0 !important;
                padding: 12px 16px;
            }
        }


    </style>
</head>
<body>
    <!-- Page principale simul√©e -->
    <div style="padding: 50px; text-align: center; color: #333;">
        <h1 style="color: #1e3a8a; margin-bottom: 20px;">Bienvenue sur notre site</h1>
        <p style="font-size: 18px; color: #666; max-width: 600px; margin: 0 auto;">
            D√©couvrez nos services et n'h√©sitez pas √† utiliser notre assistant ALEX pour toute question.
        </p>
        <div style="margin-top: 40px; padding: 40px; background: #f8f9fa; border-radius: 15px; max-width: 800px; margin: 40px auto;">
            <h2 style="color: #2563eb;">Services Accel Tech</h2>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-top: 20px;">
                <div style="background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
                    <h3 style="color: #1e3a8a;">Modernisation</h3>
                    <p>Transformation digitale de votre entreprise</p>
                </div>
                <div style="background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
                    <h3 style="color: #1e3a8a;">Innovation</h3>
                    <p>Solutions technologiques avanc√©es</p>
                </div>
                <div style="background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
                    <h3 style="color: #1e3a8a;">Consulting</h3>
                    <p>Accompagnement personnalis√©</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Bouton flottant pour ouvrir le chat -->
    <button class="chat-toggle-btn" id="chatToggle" onclick="toggleChat()">
        üí¨
    </button>

    <!-- Widget de chat -->
    <div class="chat-widget" id="chatWidget">
        <div class="container">
            <div class="chat-header">
                <button class="close-chat-btn" onclick="toggleChat()">√ó</button>
                <h1>ALEX by Accel Tech</h1>
                <p>Modernize. Innovate.</p>
            </div>

        <div class="chat-container" id="chatContainer">
            <div class="message assistant-message">
                Bonjour ! Je suis ALEX, l'assistant IA d'Accel Tech. Modernize. Innovate. Comment puis-je vous accompagner dans votre transformation digitale aujourd'hui ?
            </div>
        </div>

            <div class="loading" id="loading">
                <div class="typing"></div>
                <span>ALEX r√©fl√©chit<span class="loading-dots"></span></span>
            </div>

            <div class="chat-input-section">
                <div class="input-section">
                    <input type="text" id="messageInput" placeholder="Posez votre question √† ALEX..." onkeypress="checkEnter(event)">
                    <button class="send-btn" id="sendBtn" onclick="sendMessage()">
                        Envoyer
                    </button>
                </div>
            </div>
        </div>



    </div>

    <script>
        // Gestion du widget de chat
        function toggleChat() {
            const widget = document.getElementById('chatWidget');
            const toggleBtn = document.getElementById('chatToggle');
            
            if (widget.classList.contains('open')) {
                // Fermer le chat
                widget.classList.remove('open');
                toggleBtn.innerHTML = 'üí¨';
                toggleBtn.classList.remove('active');
                toggleBtn.style.transform = 'scale(1)';
            } else {
                // Ouvrir le chat
                widget.classList.add('open');
                toggleBtn.innerHTML = '‚úï';
                toggleBtn.classList.add('active');
                toggleBtn.style.transform = 'scale(0.9)';
                
                // Focus sur l'input
                setTimeout(() => {
                    document.getElementById('messageInput').focus();
                }, 300);
            }
        }

        function checkEnter(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }

        async function sendMessage() {
            const input = document.getElementById('messageInput');
            const message = input.value.trim();
            
            if (!message) return;

            const chatContainer = document.getElementById('chatContainer');
            const sendBtn = document.getElementById('sendBtn');
            const loading = document.getElementById('loading');

            // Ajouter le message utilisateur
            const userMessage = document.createElement('div');
            userMessage.className = 'message user-message';
            userMessage.textContent = message;
            chatContainer.appendChild(userMessage);

            // Vider l'input et d√©sactiver le bouton
            input.value = '';
            sendBtn.disabled = true;
            loading.style.display = 'block';
            
            // Faire d√©filer vers le bas
            chatContainer.scrollTop = chatContainer.scrollHeight;

            try {
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ message: message })
                });

                const data = await response.json();

                // Ajouter la r√©ponse de l'assistant avec effet de frappe
                const assistantMessage = document.createElement('div');
                assistantMessage.className = 'message assistant-message';
                assistantMessage.innerHTML = '';
                chatContainer.appendChild(assistantMessage);
                
                // Effet de frappe
                const textSpan = document.createElement('span');
                assistantMessage.appendChild(textSpan);
                typewriterEffect(textSpan, data.response, 20);
                
                // Ajouter les effets de survol
                setTimeout(() => addMessageEffects(), 1000);

            } catch (error) {
                const errorMessage = document.createElement('div');
                errorMessage.className = 'message assistant-message';
                errorMessage.textContent = 'D√©sol√©, une erreur s\\'est produite. Veuillez r√©essayer.';
                errorMessage.style.color = '#e74c3c';
                chatContainer.appendChild(errorMessage);
            }

            // R√©activer le bouton et cacher le loading
            sendBtn.disabled = false;
            loading.style.display = 'none';
            
            // Faire d√©filer vers le bas
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function clearChat() {
            const chatContainer = document.getElementById('chatContainer');
            
            // Animation de fade out
            chatContainer.style.opacity = '0.5';
            chatContainer.style.transform = 'scale(0.95)';
            
            setTimeout(() => {
                chatContainer.innerHTML = `
                    <div class="message assistant-message">
                        Bonjour ! Je suis ALEX, l'assistant IA d'Accel Tech. Comment puis-je vous accompagner aujourd'hui ?
                    </div>
                `;
                
                // Animation de fade in
                chatContainer.style.opacity = '1';
                chatContainer.style.transform = 'scale(1)';
            }, 200);
        }

        // Effets au survol des messages
        function addMessageEffects() {
            const messages = document.querySelectorAll('.message');
            messages.forEach(message => {
                message.addEventListener('mouseenter', function() {
                    this.style.transform = 'translateY(-2px) scale(1.01)';
                });
                
                message.addEventListener('mouseleave', function() {
                    this.style.transform = 'translateY(0) scale(1)';
                });
            });
        }

        // Effet de frappe pour les r√©ponses
        function typewriterEffect(element, text, speed = 30) {
            element.textContent = '';
            let i = 0;
            const timer = setInterval(() => {
                if (i < text.length) {
                    element.textContent += text.charAt(i);
                    i++;
                } else {
                    clearInterval(timer);
                }
            }, speed);
        }

        // Initialisation au chargement
        window.onload = function() {
            addMessageEffects();
            
            // Animation d'entr√©e du bouton flottant
            const toggleBtn = document.getElementById('chatToggle');
            toggleBtn.style.opacity = '0';
            toggleBtn.style.transform = 'scale(0.5)';
            
            setTimeout(() => {
                toggleBtn.style.transition = 'all 0.5s cubic-bezier(0.4, 0, 0.2, 1)';
                toggleBtn.style.opacity = '1';
                toggleBtn.style.transform = 'scale(1)';
            }, 500);
        };




    </script>
    
    <!-- Footer Accel Tech -->
    <div style="position: fixed; bottom: 15px; right: 20px; 
                color: rgba(255, 255, 255, 0.7); font-size: 12px; 
                background: rgba(0, 0, 0, 0.3); padding: 8px 15px; 
                border-radius: 20px; backdrop-filter: blur(10px);
                border: 1px solid rgba(255, 255, 255, 0.1);
                z-index: 1000;">
        Powered by <strong>Accel Tech</strong> ‚Ä¢ Modernize. Innovate.
    </div>
</body>
</html>
"""

# Application Flask
app = Flask(__name__)

# Configuration CORS pour permettre l'int√©gration dans d'autres sites web
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response

alex_client = ALEXProClient()

@app.route('/')
def home():
    """Page d'accueil"""
    return render_template_string(HTML_TEMPLATE)

@app.route('/chat', methods=['POST'])
def chat():
    """Endpoint pour le chat"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        
        if not message:
            return jsonify({'response': 'Veuillez saisir un message.'}), 400
        
        response = alex_client.chat(message)
        return jsonify({'response': response})
        
    except Exception as e:
        logger.error(f"Erreur chat endpoint: {e}")
        return jsonify({'response': 'Une erreur s\'est produite.'}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """V√©rifie la sant√© de la connexion NVIDIA et Ollama"""
    # Test NVIDIA (chat)
    try:
        if alex_client.nvidia_client:
            _ = alex_client.nvidia_client.models.list()
            nvidia_status = "üü¢ Connect√©"
        else:
            nvidia_status = "üî¥ Client non initialis√©"
    except:
        nvidia_status = "üî¥ D√©connect√©"

    # Test Ollama (embeddings)
    try:
        test_response = requests.get(
            f"{alex_client.config.OLLAMA_BASE_URL}/api/tags",
            timeout=5
        )
        ollama_status = "üü¢ Connect√©" if test_response.status_code == 200 else "üü° R√©ponse inattendue"
    except:
        ollama_status = "üî¥ D√©connect√©"

    return jsonify({
        'nvidia_status': nvidia_status,
        'ollama_status': ollama_status,
        'nvidia_url': alex_client.config.NVIDIA_BASE_URL,
        'ollama_url': alex_client.config.OLLAMA_BASE_URL,
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
    })

@app.route('/status', methods=['GET'])
def get_status():
    """Endpoint pour obtenir le statut de l'indexation"""
    try:
        # Obtenir le statut d√©taill√© de la surveillance
        surveillance_details = alex_client.get_surveillance_status()
        
        # V√©rifier le statut de la surveillance
        if surveillance_details['active'] and surveillance_details['observer_alive']:
            surveillance_status = "‚úÖ Active (Auto-indexation ON)"
            auto_indexing = True
        elif surveillance_details['active'] and not surveillance_details['observer_alive']:
            surveillance_status = "‚ùå Observer mort - Red√©marrage n√©cessaire"
            auto_indexing = False
        else:
            surveillance_status = "‚è∏Ô∏è Inactive"
            auto_indexing = False
        
        # Lister les fichiers r√©cents non index√©s
        recent_files = []
        for file_path in alex_client.watch_dir.rglob('*'):
            if file_path.is_file() and alex_client.is_supported_file(str(file_path)):
                if not alex_client.is_file_already_indexed(str(file_path)):
                    recent_files.append(str(file_path))
        
        # Calculer le temps depuis la derni√®re activit√©
        last_activity_ago = time.time() - surveillance_details['last_activity'] if surveillance_details['last_activity'] > 0 else None
        
        status = {
            'indexed_files_count': len(alex_client.indexed_files),
            'watch_directory': str(alex_client.watch_dir.absolute()),
            'directory_exists': surveillance_details['directory_exists'],
            'supported_extensions': alex_client.config.SUPPORTED_EXTENSIONS,
            'indexed_files': [Path(f).name for f in alex_client.indexed_files.keys()],
            'non_indexed_files': [Path(f).name for f in recent_files],
            'surveillance_status': surveillance_status,
            'auto_indexing': auto_indexing,
            'observer_alive': surveillance_details['observer_alive'],
            'last_activity_seconds_ago': int(last_activity_ago) if last_activity_ago else None,
            'failed_auto_files_count': surveillance_details['failed_files'],
            'failed_auto_files': surveillance_details['failed_files_list']
        }
        return jsonify(status)
    except Exception as e:
        logger.error(f"Erreur status endpoint: {e}")
        return jsonify({'error': 'Erreur r√©cup√©ration statut'}), 500

@app.route('/force_check_new', methods=['POST'])
def force_check_new():
    """Force la v√©rification et indexation des nouveaux fichiers"""
    try:
        logger.info("üîç V√©rification manuelle des nouveaux fichiers...")
        
        new_files_indexed = 0
        failed_files = []
        
        # Traiter d'abord les fichiers qui ont √©chou√© en auto-indexation
        if hasattr(alex_client, '_failed_auto_files') and alex_client._failed_auto_files:
            logger.info(f"üîß Reprise des fichiers √©chou√©s en auto: {len(alex_client._failed_auto_files)}")
            for file_path in alex_client._failed_auto_files[:]:  # Copie pour √©viter modification pendant it√©ration
                try:
                    if os.path.exists(file_path) and alex_client.is_supported_file(file_path):
                        logger.info(f"üîÑ Reprise indexation √©chou√©e: {Path(file_path).name}")
                        alex_client.index_file(file_path)
                        alex_client._failed_auto_files.remove(file_path)
                        new_files_indexed += 1
                except Exception as e:
                    logger.error(f"‚ùå √âchec reprise indexation {Path(file_path).name}: {e}")
                    failed_files.append(Path(file_path).name)
        
        # Ensuite traiter les nouveaux fichiers
        for file_path in alex_client.watch_dir.rglob('*'):
            if file_path.is_file() and alex_client.is_supported_file(str(file_path)):
                if not alex_client.is_file_already_indexed(str(file_path)):
                    try:
                        logger.info(f"üÜï Indexation nouveau fichier: {file_path.name}")
                        alex_client.index_file(str(file_path))
                        new_files_indexed += 1
                    except Exception as e:
                        logger.error(f"‚ùå √âchec indexation {file_path.name}: {e}")
                        failed_files.append(file_path.name)
        
        message = f'{new_files_indexed} nouveaux fichiers index√©s'
        if failed_files:
            message += f', {len(failed_files)} √©checs'
        
        return jsonify({
            'message': message,
            'total_indexed': len(alex_client.indexed_files),
            'new_files_indexed': new_files_indexed,
            'failed_files': failed_files[:5],  # Limiter √† 5 pour √©viter les r√©ponses trop longues
            'remaining_failed': len(alex_client._failed_auto_files) if hasattr(alex_client, '_failed_auto_files') else 0
        })
        
    except Exception as e:
        logger.error(f"Erreur check nouveaux fichiers: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/restart_watcher', methods=['POST'])
def restart_watcher():
    """Red√©marre la surveillance automatique"""
    try:
        logger.info("üîÑ Red√©marrage de la surveillance automatique...")
        
        # Arr√™ter l'ancien watcher
        if alex_client.observer and alex_client.observer.is_alive():
            alex_client.observer.stop()
            alex_client.observer.join()
            logger.info("üõë Ancien watcher arr√™t√©")
        
        # Red√©marrer
        success = alex_client.start_file_watcher()
        
        if success:
            return jsonify({
                'message': 'Surveillance automatique red√©marr√©e avec succ√®s',
                'status': 'active',
                'watch_directory': str(alex_client.watch_dir)
            })
        else:
            return jsonify({
                'message': '√âchec red√©marrage surveillance automatique',
                'status': 'failed'
            }), 500
            
    except Exception as e:
        logger.error(f"Erreur restart_watcher: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/force_full_reindex', methods=['POST'])
def force_full_reindex():
    """Force la r√©indexation compl√®te de TOUS les fichiers (ignore le cache)"""
    try:
        # Diagnostic avant indexation
        logger.info(f"üîç R√âINDEXATION FORC√âE COMPL√àTE")
        
        # Lister tous les fichiers support√©s
        supported_files = []
        for file_path in alex_client.watch_dir.rglob('*'):
            if file_path.is_file() and alex_client.is_supported_file(str(file_path)):
                supported_files.append(str(file_path))
        
        # VIDER COMPL√àTEMENT le cache et ChromaDB
        alex_client.indexed_files.clear()
        try:
            if hasattr(alex_client, 'collection') and alex_client.collection:
                alex_client.create_vector_store()
                logger.info("üóëÔ∏è Base vectorielle et cache compl√®tement vid√©s")
        except Exception as e:
            logger.warning(f"  Erreur vidage: {e}")
        
        # Indexation compl√®te
        alex_client.scan_existing_files()
        
        return jsonify({
            'message': f'R√©indexation COMPL√àTE termin√©e: {len(supported_files)} fichiers retrait√©s',
            'indexed_count': len(alex_client.indexed_files),
            'files_found': len(supported_files),
            'cache_cleared': True
        })
    except Exception as e:
        logger.error(f"Erreur force_full_reindex: {e}")
        return jsonify({'error': 'Erreur r√©indexation compl√®te'}), 500

@app.route('/production_reset', methods=['POST'])
def production_reset():
    """NETTOYAGE COMPLET POUR LA PRODUCTION - Supprime TOUT et recommence"""
    try:
        logger.info("üöÄ NETTOYAGE COMPLET POUR LA PRODUCTION")
        logger.info("=" * 60)
        
        # 1. Arr√™ter la surveillance
        if alex_client.observer and alex_client.observer.is_alive():
            alex_client.observer.stop()
            alex_client.observer.join()
            logger.info("üõë Surveillance automatique arr√™t√©e")
        
        # 2. SUPPRIMER COMPL√àTEMENT la base ChromaDB
        logger.info("üóëÔ∏è SUPPRESSION COMPL√àTE de la base ChromaDB...")
        try:
            # Supprimer toutes les collections existantes
            collections = alex_client.chroma_client.list_collections()
            for collection in collections:
                alex_client.chroma_client.delete_collection(collection.name)
                logger.info(f"   ‚ùå Collection supprim√©e: {collection.name}")
            
            # Cr√©er une nouvelle collection vierge
            alex_client.collection = alex_client.chroma_client.create_collection(
                name="alex_pro_docs_production",
                metadata={"description": "Documents ALEX - Production Clean"}
            )
            logger.info("‚úÖ Nouvelle collection production cr√©√©e")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur suppression ChromaDB: {e}")
            # Fallback: cr√©er une nouvelle collection
            alex_client.collection = alex_client.chroma_client.create_collection(
                name=f"alex_production_{int(time.time())}",
                metadata={"description": "Documents ALEX - Production"}
            )
        
        # 3. VIDER COMPL√àTEMENT le cache local
        alex_client.indexed_files.clear()
        alex_client._failed_auto_files.clear() if hasattr(alex_client, '_failed_auto_files') else None
        logger.info("üßπ Cache local compl√®tement vid√©")
        
        # 4. Compter les fichiers √† traiter
        production_files = []
        for file_path in alex_client.watch_dir.rglob('*'):
            if file_path.is_file() and alex_client.is_supported_file(str(file_path)):
                production_files.append(str(file_path))
        
        logger.info(f"üìä Fichiers d√©tect√©s pour la production: {len(production_files)}")
        for file_path in production_files:
            logger.info(f"   üìÑ {Path(file_path).name}")
        
        # 5. INDEXATION COMPL√àTE POUR LA PRODUCTION
        if production_files:
            logger.info("üöÄ D√âBUT INDEXATION PRODUCTION...")
            alex_client.scan_existing_files()
            logger.info("‚úÖ INDEXATION PRODUCTION TERMIN√âE")
        else:
            logger.warning("‚ö†Ô∏è Aucun fichier trouv√© pour l'indexation")
        
        # 6. Red√©marrer la surveillance
        logger.info("üîÑ Red√©marrage de la surveillance automatique...")
        alex_client.start_file_watcher()
        
        # 7. Statistiques finales
        final_stats = {
            'total_files_found': len(production_files),
            'files_indexed': len(alex_client.indexed_files),
            'collection_name': alex_client.collection.name if alex_client.collection else 'None',
            'files_list': [Path(f).name for f in production_files],
            'indexed_files_list': [Path(f).name for f in alex_client.indexed_files.keys()],
            'surveillance_restarted': alex_client.observer.is_alive() if alex_client.observer else False
        }
        
        logger.info("=" * 60)
        logger.info("üéØ NETTOYAGE PRODUCTION TERMIN√â")
        logger.info(f"üìä Fichiers index√©s: {final_stats['files_indexed']}/{final_stats['total_files_found']}")
        logger.info("=" * 60)
        
        return jsonify({
            'message': 'üöÄ Base de donn√©es compl√®tement nettoy√©e et r√©initialis√©e pour la production',
            'status': 'production_ready',
            **final_stats
        })
        
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage production: {e}")
        return jsonify({'error': f'Erreur nettoyage production: {str(e)}'}), 500

@app.route('/reindex', methods=['POST'])
def smart_reindex():
    """R√©indexation intelligente (respecte le cache des fichiers d√©j√† index√©s)"""
    try:
        # Diagnostic avant indexation
        logger.info(f"üîç Scan du dossier: {alex_client.config.WATCH_DIRECTORY}")
        
        # Lister tous les fichiers support√©s
        supported_files = []
        for file_path in alex_client.watch_dir.rglob('*'):
            if file_path.is_file() and alex_client.is_supported_file(str(file_path)):
                supported_files.append(str(file_path))
        
        logger.info(f"   {len(supported_files)} fichiers support√©s trouv√©s:")
        for file_path in supported_files:
            logger.info(f"   - {Path(file_path).name}")
        
        # Vider le cache ChromaDB compl√®tement
        try:
            if hasattr(alex_client, 'collection') and alex_client.collection:
                alex_client.create_vector_store()
                logger.info("üóëÔ∏è Base vectorielle vid√©e compl√®tement")
            else:
                logger.info("üîÑ Cr√©ation nouvelle base vectorielle")
                alex_client.create_vector_store()
        except Exception as e:
            logger.warning(f"  Erreur vidage base: {e}")
            # Fallback : cr√©er une nouvelle collection
            try:
                alex_client.create_vector_store()
            except Exception as e2:
                logger.error(f"  Erreur cr√©ation base: {e2}")
        
        # NE PAS vider le cache local - garder la m√©moire des fichiers index√©s
        # alex_client.indexed_files.clear()  # COMMENT√â pour √©viter r√©indexation
        
        # Relancer le scan avec respect du cache
        try:
            alex_client.scan_existing_files()
            already_indexed = len([f for f in supported_files if alex_client.is_file_already_indexed(f)])
            newly_indexed = len(alex_client.indexed_files) - already_indexed
            message = f'Scan termin√©: {already_indexed} d√©j√† index√©s, {newly_indexed} nouveaux fichiers trait√©s'
            logger.info(f"‚úÖ Indexation termin√©e: {len(alex_client.indexed_files)} fichiers au total")
        except Exception as e:
            logger.error(f"Erreur lors de l'indexation: {e}")
            message = f'R√©indexation √©chou√©e: V√©rifiez la connexion Ollama (embeddings)'
        
        return jsonify({
            'message': message,
            'indexed_count': len(alex_client.indexed_files),
            'files_found': len(supported_files),
            'files_list': [Path(f).name for f in supported_files[:5]]  # Top 5 files
        })
    except Exception as e:
        logger.error(f"Erreur reindex endpoint: {e}")
        return jsonify({'error': 'Erreur r√©indexation'}), 500

@app.route('/start_indexing', methods=['POST'])
def start_indexing():
    """D√©marre l'indexation initiale"""
    try:
        alex_client.scan_existing_files()
        return jsonify({
            'message': 'Indexation d√©marr√©e',
            'indexed_count': len(alex_client.indexed_files)
        })
    except Exception as e:
        logger.error(f"Erreur start_indexing: {e}")
        return jsonify({'error': f'Erreur indexation: {str(e)}'}), 500

@app.route('/diagnostic', methods=['GET'])
def diagnostic_files():
    """Diagnostic des fichiers index√©s"""
    try:
        # Lister tous les fichiers du dossier
        all_files = []
        supported_files = []
        indexed_files = list(alex_client.indexed_files.keys())
        
        for file_path in alex_client.watch_dir.rglob('*'):
            if file_path.is_file():
                all_files.append(str(file_path))
                if alex_client.is_supported_file(str(file_path)):
                    supported_files.append(str(file_path))
        
        # Compter les √©l√©ments dans ChromaDB avec diagnostic
        try:
            collection_count = alex_client.vector_store.count()
            logger.info(f"üìä ChromaDB count: {collection_count}")
        except Exception as e:
            logger.error(f"  Erreur ChromaDB count: {e}")
            collection_count = 0
            
        # V√©rifier la collection elle-m√™me
        try:
            # Essayer de r√©cup√©rer quelques documents pour tester
            test_results = alex_client.vector_store.peek(limit=5)
            actual_chunks = len(test_results.get('documents', []))
            logger.info(f"üîç Documents r√©els dans ChromaDB: {actual_chunks}")
            if actual_chunks > collection_count:
                collection_count = actual_chunks
        except Exception as e:
            logger.warning(f"  Erreur peek ChromaDB: {e}")
        
        return jsonify({
            'dossier_surveille': alex_client.config.WATCH_DIRECTORY,
            'fichiers_totaux': len(all_files),
            'fichiers_supportes': len(supported_files),
            'fichiers_indexes': len(indexed_files),
            'chunks_chromadb': collection_count,
            'liste_supportes': [Path(f).name for f in supported_files],
            'liste_indexes': [Path(f).name for f in indexed_files],
            'formats_supportes': ['.pdf', '.txt', '.docx', '.odt']
        })
    except Exception as e:
        logger.error(f"Erreur diagnostic: {e}")
        return jsonify({'error': f'Erreur diagnostic: {str(e)}'}), 500


@app.route('/debug_context', methods=['POST'])
def debug_context():
    """Debug endpoint pour voir le contexte r√©el"""
    try:
        data = request.get_json()
        query = data.get('query', '')
        
        if not query:
            return jsonify({'error': 'Query manquante'}), 400
        
        # Recherche avec debug
        context = alex_client.search_context(query, limit=3)
        
        # R√©cup√©rer aussi quelques documents de ChromaDB
        try:
            sample_docs = alex_client.collection.peek(limit=3)
            sample_content = sample_docs.get('documents', [])[:3] if sample_docs else []
        except:
            sample_content = []
        
        return jsonify({
            'query': query,
            'context_found': context,
            'context_length': len(context) if context else 0,
            'sample_documents': sample_content,
            'collection_count': alex_client.collection.count() if alex_client.collection else 0
        })
        
    except Exception as e:
        logger.error(f"Erreur debug_context: {e}")
        return jsonify({'error': f'Erreur: {str(e)}'}), 500

def cleanup():
    """Nettoyage √† la fermeture"""
    try:
        if hasattr(alex_client, 'observer') and alex_client.observer:
            alex_client.observer.stop()
            alex_client.observer.join()
            logger.info("üõë Surveillance arr√™t√©e proprement")
    except Exception as e:
        logger.error(f"Erreur lors de l'arr√™t: {e}")

def app_taipy():
    """Lance l'application ALEX"""
    print("   D√©marrage d'ALEX...")
    print("=" * 50)
    print(f"üîó Configuration Hybride:")
    print(f"   Chat (NVIDIA NIM): {ALEXProConfig.NVIDIA_CHAT_MODEL}")
    print(f"   Embeddings (Ollama): {ALEXProConfig.OLLAMA_EMBEDDING_MODEL}")
    print(f"   Ollama URL: {ALEXProConfig.OLLAMA_BASE_URL}")
    print(f"   R√©pertoire surveill√©: {ALEXProConfig.WATCH_DIRECTORY}")
    print("üåê D√©marrage de l'interface...")
    
    try:
        app.run(
            host="0.0.0.0",
            port=8505,
            debug=False
        )
    except KeyboardInterrupt:
        print("\nüëã Arr√™t d'ALEX...")
        cleanup()
    except Exception as e:
        print(f"  Erreur: {e}")
        cleanup()

if __name__ == "__main__":
    import atexit
    atexit.register(cleanup)
    app_taipy()
